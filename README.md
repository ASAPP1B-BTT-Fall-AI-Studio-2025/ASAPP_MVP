# Extractify

A beautiful, modern Next.js application that uses advanced AI/ML techniques to extract structured data from unstructured conversation text. Extractify provides an intuitive interface for uploading conversation files or inputting text directly to extract key information like email addresses, phone numbers, ZIP codes, and order IDs.

## âœ¨ Features

- **ğŸ¨ Modern UI/UX**: Beautiful gradient design with smooth animations and transitions
- **ğŸ“ File Upload**: Intuitive drag-and-drop interface supporting .txt, .csv, .json files
- **âœï¸ Text Input**: Direct text input for real-time conversation processing
- **ğŸ¤– AI-Powered Extraction**: Enhanced regex patterns with optional LLM integration
- **ğŸ“Š Conversation Management**: Persistent storage with SQLite database
- **ğŸ’¾ Data Export**: Download extracted fields as JSON
- **ğŸ“± Responsive Design**: Optimized for desktop, tablet, and mobile devices
- **âš¡ Real-time Processing**: Instant field extraction and validation

## ğŸ¨ Design Philosophy

Extractify features a modern gradient-based design with:
- **Smooth Color Transitions**: Blue to purple gradients throughout the interface
- **Interactive Elements**: Hover effects, scale transforms, and smooth transitions
- **Accessibility First**: Clear contrast ratios and semantic HTML structure
- **Component-Based Architecture**: Modular, reusable React components

## Technology Stack

- **Frontend**: Next.js 15, React, TypeScript, Tailwind CSS
- **Backend**: Next.js API Routes
- **Icons**: Lucide React
- **Machine Learning**: Custom regex-based field extraction (based on Jupyter notebook analysis)

## ğŸ—ï¸ Project Structure

```
ASAPP_MVP/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ conversations/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ [id]/            # Individual conversation details
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ route.ts         # CRUD operations for conversations
â”‚   â”‚   â”‚   â””â”€â”€ extract/
â”‚   â”‚   â”‚       â””â”€â”€ route.ts         # Field extraction API
â”‚   â”‚   â”œâ”€â”€ globals.css              # Global styles with gradients
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx                 # Main application page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ConversationHistory.tsx  # Left sidebar conversation list
â”‚   â”‚   â”œâ”€â”€ ConversationInput.tsx    # Text input component
â”‚   â”‚   â”œâ”€â”€ ExtractedFieldsDisplay.tsx # Right sidebar results
â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx           # Drag & drop file upload
â”‚   â”‚   â””â”€â”€ Header.tsx               # Navigation with Extractify branding
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ database.ts              # SQLite database operations
â”‚       â”œâ”€â”€ fieldExtractor.ts        # Basic extraction logic
â”‚       â”œâ”€â”€ enhancedFieldExtractor.ts # Advanced extraction with FastAPI integration
â”‚       â””â”€â”€ ml/                      # Original ML analysis notebooks
â”œâ”€â”€ data/
â”‚   â””â”€â”€ extractify.db                # SQLite database file
â”œâ”€â”€ sample-data/
â”‚   â””â”€â”€ sample-conversation.txt      # Test data for extraction
â””â”€â”€ public/                          # Static assets
```

## Getting Started

### Prerequisites

- Node.js 18.x or later
- npm or yarn package manager

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd ASAPP_MVP
```

2. Install dependencies:
```bash
npm install
```

3. Run the development server:
```bash
npm run dev
```

4. Open [http://localhost:3000](http://localhost:3000) in your browser.

## Usage

### Text Input Method
1. Type or paste conversation text into the "Input Conversation" section
2. Click "Extract Fields" to process the text
3. View extracted fields in the right sidebar

### File Upload Method
1. Drag and drop a file into the upload area or click "browse" to select a file
2. Supported formats: .txt, .csv, .json
3. The file will be automatically processed upon upload
4. View extracted fields and conversation history

### Field Extraction

The application extracts four main types of fields:

- **Email**: Standard email address patterns
- **Phone**: Phone numbers with format (XXX) XXX-XXXX
- **ZIP Code**: 5-digit US ZIP codes
- **Order ID**: Various order ID formats including:
  - "order" followed by alphanumeric
  - "order id/number" patterns
  - Hash symbol followed by alphanumeric
  - Standalone alphanumeric order-like strings

### Conversation Management

- All processed conversations are stored in memory (production should use a database)
- Click on conversation history items to view previous extractions
- Conversations include metadata like processing date and file information

## API Endpoints

### POST /api/extract
Extract fields from conversation text.

**Request Body:**
```json
{
  "text": "conversation text here",
  "fileName": "optional-file-name.txt"
}
```

**Response:**
```json
{
  "email": "user@example.com",
  "phone": "(555) 123-4567",
  "zipCode": "12345",
  "orderId": "ORD123456",
  "metadata": {
    "fileName": "conversation.txt",
    "processedAt": "2024-01-01T00:00:00.000Z",
    "textLength": 150
  }
}
```

### GET /api/conversations
Retrieve all stored conversations.

### POST /api/conversations
Store a new conversation with extracted fields.

### DELETE /api/conversations?id=<id>
Delete a specific conversation.

## Development

### Running Tests
```bash
npm test
```

### Building for Production
```bash
npm run build
npm start
```

### Linting
```bash
npm run lint
```

## Future Enhancements

Based on the mockup design, planned features include:

1. **Authentication System**
   - GitHub OAuth integration
   - Google OAuth integration
   - Email/password authentication

2. **Advanced Analytics**
   - Batch conversation processing
   - EDA visualizations
   - Extraction accuracy metrics

3. **Database Integration**
   - Persistent conversation storage
   - User management
   - Audit trails

4. **Enhanced ML Models**
   - Integration with more sophisticated NLP models
   - Custom field type definitions
   - Confidence scoring

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.
